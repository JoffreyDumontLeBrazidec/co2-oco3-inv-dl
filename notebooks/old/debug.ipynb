{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53ecf53-fa78-49b0-bfb4-1d22c80dff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 19:07:18.562796: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1920x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/cerea_raid/users/dumontj/dev/coco2/dl\")\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib_functions\n",
    "from typing import List, Optional\n",
    "matplotlib_functions.setMatplotlibParam()\n",
    "plt.viridis()\n",
    "import joblib\n",
    "import pickle\n",
    "from include.generators import Generator\n",
    "from saver import Saver\n",
    "from include.callbacks import get_modelcheckpoint, ExtraValidation\n",
    "\n",
    "import model_eval\n",
    "from Data import Data_train, Data_eval\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback, WandbMetricsLogger\n",
    "import models.reg as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5307af57-bade-41b7-9f3c-407c9cb54aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_save_dir = \"/cerea_raid/users/dumontj/dev/coco2/dl/nb_train/sim/\"\n",
    "project_name = \"test_to_delete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e2509e-d07c-44ac-ad28-d4fa7b2d8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_nc = \"/libre/dumontj/coco2/dl-input/2km_forBox/train_dataset.nc\"\n",
    "path_valid_nc = \"/libre/dumontj/coco2/dl-input/2km_forBox/valid_dataset.nc\"\n",
    "path_extra_valid_nc = \"/libre/dumontj/coco2/dl-input/2km_Box/valid_dataset.nc\"\n",
    "\n",
    "save_dir = os.path.join(general_save_dir, \"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264d8d04-9eb3-4524-a647-f0cd8f57c171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 19:07:26.200082: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 19:07:26.714067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14482 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.x.train.shape (47160, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "data = Data_train(path_train_nc, path_valid_nc, path_extra_valid_nc)\n",
    "data.prepare_input(\"xco2\")\n",
    "data.prepare_output_inversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a4c59e-f843-4e0f-8e36-5042b4a6ec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoffreydumont\u001b[0m (\u001b[33mcerea-daml\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cerea_raid/users/dumontj/dev/coco2/dl/wandb/run-20230228_190733-1h32og1y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cerea-daml/test_to_delete/runs/1h32og1y\" target=\"_blank\">xco2_prec_winds_noisy_boolperfseg_modelX</a></strong> to <a href=\"https://wandb.ai/cerea-daml/test_to_delete\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/cerea-daml/test_to_delete/runs/1h32og1y?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f06281b28b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"xco2_prec_winds_noisy_boolperfseg_modelX\"\n",
    "wandb.init(project=project_name, name=exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51aee84-1ff9-48aa-9a07-dcc36ec32209",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = get_modelcheckpoint(True, [], os.path.join(save_dir, exp_name, \"w_best.h5\"))\n",
    "history = ExtraValidation((data.x.extra_valid, data.y.extra_valid))\n",
    "cbs.append(WandbMetricsLogger())\n",
    "cbs.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeebc65c-fbd5-475f-9865-c5e9f4f3665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_builder = rm.Reg_model_builder(\n",
    "    \"essential\",\n",
    "    data.x.fields_input_shape,\n",
    "    data.y.classes,\n",
    "    data.x.n_layer,\n",
    "    data.x.xco2_noisy_chans,\n",
    ")\n",
    "model = reg_builder.get_model()\n",
    "model.compile(\"adam\", \"MeanAbsoluteError\", metrics=tf.keras.losses.MeanAbsolutePercentageError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff7e5a93-14a4-4bdf-98e2-75d53f05e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 19:07:37.011947: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/model/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-02-28 19:07:37.748690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2023-02-28 19:07:38.308431: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-28 19:07:38.663328: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x556c89c48070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-28 19:07:38.663390: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 5000, Compute Capability 7.5\n",
      "2023-02-28 19:07:38.674049: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-28 19:07:38.737832: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-28 19:07:38.788603: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474/1474 [==============================] - ETA: 0s - loss: 8.3798 - mean_absolute_percentage_error: 45.8378\n",
      "Epoch 1: val_loss improved from inf to 7.77569, saving model to /cerea_raid/users/dumontj/dev/coco2/dl/nb_train/sim/box/xco2_prec_winds_noisy_boolperfseg_modelX/w_best.h5\n",
      "extra_val_loss: [6.094306468963623, 30.839372634887695]\n",
      "1474/1474 [==============================] - 26s 15ms/step - loss: 8.3798 - mean_absolute_percentage_error: 45.8378 - val_loss: 7.7757 - val_mean_absolute_percentage_error: 38.5127\n",
      "Epoch 2/2\n",
      "1473/1474 [============================>.] - ETA: 0s - loss: 7.6469 - mean_absolute_percentage_error: 42.1079\n",
      "Epoch 2: val_loss improved from 7.77569 to 7.48140, saving model to /cerea_raid/users/dumontj/dev/coco2/dl/nb_train/sim/box/xco2_prec_winds_noisy_boolperfseg_modelX/w_best.h5\n",
      "extra_val_loss: [5.344578742980957, 27.591793060302734]\n",
      "1474/1474 [==============================] - 21s 14ms/step - loss: 7.6458 - mean_absolute_percentage_error: 42.1047 - val_loss: 7.4814 - val_mean_absolute_percentage_error: 39.7854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f070f90c0a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data.x.train,\n",
    "    data.y.train,\n",
    "    epochs=2,\n",
    "    callbacks=cbs,\n",
    "    validation_data=(data.x.valid, data.y.valid),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1065cdad-49d3-47d9-addc-558334d5b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = [5.06552791595459, 26.34125518798828]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da3efc0-52e7-4022-a9dc-451ff68b70cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if type(u) == list:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e56f35-2e54-420b-ad10-0fba8460fd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 19:09:59.976649: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cerea_raid/users/dumontj/dev/coco2/dl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerea_raid/users/dumontj/dev/coco2/dl/main.py:18: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"cfg\", config_name=\"config\")\n",
      "/profils_cerea/dumontj/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Run begins \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "data:\n",
      "  split:\n",
      "    type: regular\n",
      "    train:\n",
      "      ratio: 0.85\n",
      "  input:\n",
      "    dir_seg_models: /cerea_raid/users/dumontj/dev/coco2/dl/res/models\n",
      "    chan_0: xco2\n",
      "    chan_1: xco2_prec\n",
      "    chan_2: v_wind\n",
      "    chan_3: u_wind\n",
      "    chan_4: bool_perf_seg\n",
      "  output:\n",
      "    N_emissions: 1\n",
      "  path:\n",
      "    directory: /libre/dumontj/coco2/dl-input\n",
      "    train:\n",
      "      name: 2km_forLip_2\n",
      "      nc: train_dataset.nc\n",
      "    valid:\n",
      "      name: 2km_Lip\n",
      "      nc: valid_dataset.nc\n",
      "    extra_valid:\n",
      "      name: 2km_forLip_2\n",
      "      nc: valid_dataset.nc\n",
      "dir_res: res/inversion\n",
      "exp_name: inv_lip_perf_seg\n",
      "seed: 42\n",
      "sweep: true\n",
      "model:\n",
      "  type: inversion\n",
      "  name: essential\n",
      "  loss_func: MeanAbsoluteError\n",
      "  dropout_rate: 0.2\n",
      "  scaling_coefficient: 1\n",
      "training:\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.001\n",
      "  max_epochs: 500\n",
      "  init_weights: random\n",
      "  optimiser: adam\n",
      "augmentations:\n",
      "  shuffle: true\n",
      "  rot:\n",
      "    range: 180\n",
      "  shift:\n",
      "    range: 0\n",
      "  flip:\n",
      "    bool: true\n",
      "  shear:\n",
      "    range: 90\n",
      "  zoom:\n",
      "    range: 0.2\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    __target__: true\n",
      "  learning_rate_monitor:\n",
      "    __target__: true\n",
      "    factor: 0.5\n",
      "    patience: 20\n",
      "    min_delta: 0.005\n",
      "    min_lr: 5.0e-05\n",
      "    cooldown: 0\n",
      "  wandb:\n",
      "    __target__: true\n",
      "\n",
      "[2023-02-28 19:10:07,528][wandb.jupyter][ERROR] - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoffreydumont\u001b[0m (\u001b[33mcerea-daml\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cerea-daml/inv_lip_perf_seg/runs/7bva2nrq\" target=\"_blank\">inv_lip_perf_seg</a></strong> to <a href=\"https://wandb.ai/cerea-daml/inv_lip_perf_seg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 19:10:17.068195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 19:10:17.570641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14482 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "2023-02-28 19:10:17.757545: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2060451840 exceeds 10% of free system memory.\n",
      "2023-02-28 19:10:19.029106: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2060451840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.x.train.shape (25152, 64, 64, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 19:10:23.629310: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/model/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-02-28 19:10:24.388105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2023-02-28 19:10:24.956797: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-28 19:10:25.313880: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fb9c6237400 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-28 19:10:25.313909: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 5000, Compute Capability 7.5\n",
      "2023-02-28 19:10:25.317315: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-28 19:10:25.370955: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-28 19:10:25.420670: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/786 [============================>.] - ETA: 0s - loss: 15.5986 - mean_absolute_percentage_error: 70.5511\n",
      "Epoch 1: val_loss improved from inf to 6.94532, saving model to w_best.h5\n",
      "[2023-02-28 19:10:40,901][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n",
      "[2023-02-28 19:10:42,337][tensorflow][INFO] - Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_val_loss: [9.51257610321045, 108.6522216796875]\n",
      "786/786 [==============================] - 22s 21ms/step - loss: 15.5889 - mean_absolute_percentage_error: 70.5444 - val_loss: 6.9453 - val_mean_absolute_percentage_error: 51.2059 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "783/786 [============================>.] - ETA: 0s - loss: 10.8767 - mean_absolute_percentage_error: 49.3549\n",
      "Epoch 2: val_loss improved from 6.94532 to 5.06524, saving model to w_best.h5\n",
      "[2023-02-28 19:10:57,381][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n",
      "[2023-02-28 19:10:57,870][tensorflow][INFO] - Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_val_loss: [4.978026866912842, 39.99327087402344]\n",
      "786/786 [==============================] - 15s 20ms/step - loss: 10.8676 - mean_absolute_percentage_error: 49.3073 - val_loss: 5.0652 - val_mean_absolute_percentage_error: 33.9103 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 9.2589 - mean_absolute_percentage_error: 42.0773\n",
      "Epoch 3: val_loss did not improve from 5.06524\n",
      "extra_val_loss: [6.8576202392578125, 61.4288330078125]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 9.2602 - mean_absolute_percentage_error: 42.0742 - val_loss: 5.9131 - val_mean_absolute_percentage_error: 41.0648 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 8.6765 - mean_absolute_percentage_error: 38.8663\n",
      "Epoch 4: val_loss did not improve from 5.06524\n",
      "extra_val_loss: [6.785861968994141, 59.79945373535156]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 8.6786 - mean_absolute_percentage_error: 38.8849 - val_loss: 5.8604 - val_mean_absolute_percentage_error: 40.5045 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 8.2481 - mean_absolute_percentage_error: 36.7659\n",
      "Epoch 5: val_loss improved from 5.06524 to 4.79365, saving model to w_best.h5\n",
      "[2023-02-28 19:11:38,590][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n",
      "[2023-02-28 19:11:39,073][tensorflow][INFO] - Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_val_loss: [5.869560241699219, 51.594974517822266]\n",
      "786/786 [==============================] - 16s 20ms/step - loss: 8.2468 - mean_absolute_percentage_error: 36.7769 - val_loss: 4.7937 - val_mean_absolute_percentage_error: 33.0830 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 7.8566 - mean_absolute_percentage_error: 35.2451\n",
      "Epoch 6: val_loss improved from 4.79365 to 4.16524, saving model to w_best.h5\n",
      "[2023-02-28 19:11:53,741][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n",
      "[2023-02-28 19:11:54,216][tensorflow][INFO] - Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_val_loss: [5.593883037567139, 54.356231689453125]\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 7.8566 - mean_absolute_percentage_error: 35.2451 - val_loss: 4.1652 - val_mean_absolute_percentage_error: 29.6263 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 7.6683 - mean_absolute_percentage_error: 34.3453\n",
      "Epoch 7: val_loss improved from 4.16524 to 4.15199, saving model to w_best.h5\n",
      "[2023-02-28 19:12:09,340][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n",
      "[2023-02-28 19:12:09,825][tensorflow][INFO] - Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_val_loss: [5.3892741203308105, 46.79933547973633]\n",
      "786/786 [==============================] - 15s 20ms/step - loss: 7.6683 - mean_absolute_percentage_error: 34.3453 - val_loss: 4.1520 - val_mean_absolute_percentage_error: 28.7244 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 7.5155 - mean_absolute_percentage_error: 33.7948\n",
      "Epoch 8: val_loss did not improve from 4.15199\n",
      "extra_val_loss: [5.4258198738098145, 47.732852935791016]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 7.5155 - mean_absolute_percentage_error: 33.7948 - val_loss: 4.2468 - val_mean_absolute_percentage_error: 29.4567 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "783/786 [============================>.] - ETA: 0s - loss: 7.3402 - mean_absolute_percentage_error: 33.0559\n",
      "Epoch 9: val_loss improved from 4.15199 to 3.73610, saving model to w_best.h5\n",
      "[2023-02-28 19:12:37,773][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n",
      "[2023-02-28 19:12:38,268][tensorflow][INFO] - Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_val_loss: [5.558135032653809, 50.49557113647461]\n",
      "786/786 [==============================] - 16s 20ms/step - loss: 7.3407 - mean_absolute_percentage_error: 33.0828 - val_loss: 3.7361 - val_mean_absolute_percentage_error: 25.8615 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "783/786 [============================>.] - ETA: 0s - loss: 7.3057 - mean_absolute_percentage_error: 32.5539\n",
      "Epoch 10: val_loss did not improve from 3.73610\n",
      "extra_val_loss: [5.066624641418457, 42.77330017089844]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 7.3018 - mean_absolute_percentage_error: 32.5373 - val_loss: 4.5006 - val_mean_absolute_percentage_error: 30.6445 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 7.1490 - mean_absolute_percentage_error: 31.8070\n",
      "Epoch 11: val_loss did not improve from 3.73610\n",
      "extra_val_loss: [4.689034938812256, 35.55213928222656]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 7.1504 - mean_absolute_percentage_error: 31.8068 - val_loss: 4.3422 - val_mean_absolute_percentage_error: 29.2909 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "784/786 [============================>.] - ETA: 0s - loss: 7.0097 - mean_absolute_percentage_error: 31.4412\n",
      "Epoch 12: val_loss did not improve from 3.73610\n",
      "extra_val_loss: [5.302544593811035, 45.65446090698242]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 7.0099 - mean_absolute_percentage_error: 31.4674 - val_loss: 4.1969 - val_mean_absolute_percentage_error: 29.1147 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.9307 - mean_absolute_percentage_error: 30.9664\n",
      "Epoch 13: val_loss did not improve from 3.73610\n",
      "extra_val_loss: [4.34105110168457, 34.663787841796875]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.9331 - mean_absolute_percentage_error: 30.9565 - val_loss: 4.1779 - val_mean_absolute_percentage_error: 28.4898 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.8957 - mean_absolute_percentage_error: 31.0408\n",
      "Epoch 14: val_loss did not improve from 3.73610\n",
      "extra_val_loss: [5.180920600891113, 42.89499282836914]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.8962 - mean_absolute_percentage_error: 31.0309 - val_loss: 4.3987 - val_mean_absolute_percentage_error: 30.0044 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.8388 - mean_absolute_percentage_error: 31.0524\n",
      "Epoch 15: val_loss did not improve from 3.73610\n",
      "extra_val_loss: [4.856172561645508, 43.116661071777344]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.8382 - mean_absolute_percentage_error: 31.0448 - val_loss: 4.1342 - val_mean_absolute_percentage_error: 28.7901 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.8812 - mean_absolute_percentage_error: 30.6787\n",
      "Epoch 16: val_loss improved from 3.73610 to 3.72977, saving model to w_best.h5\n",
      "[2023-02-28 19:14:10,000][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n",
      "[2023-02-28 19:14:10,499][tensorflow][INFO] - Assets written to: /cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/cerea_raid/users/dumontj/dev/coco2/dl/res/inversion/inv_lip_perf_seg/wandb/run-20230228_191010-7bva2nrq/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_val_loss: [4.679994583129883, 42.482913970947266]\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 6.8821 - mean_absolute_percentage_error: 30.6709 - val_loss: 3.7298 - val_mean_absolute_percentage_error: 25.6895 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 6.7552 - mean_absolute_percentage_error: 30.5718\n",
      "Epoch 17: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.2524919509887695, 43.63689041137695]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.7552 - mean_absolute_percentage_error: 30.5718 - val_loss: 4.2815 - val_mean_absolute_percentage_error: 30.0090 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.7520 - mean_absolute_percentage_error: 30.1210\n",
      "Epoch 18: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.475597381591797, 37.757843017578125]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.7517 - mean_absolute_percentage_error: 30.1280 - val_loss: 3.9096 - val_mean_absolute_percentage_error: 26.6914 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.6451 - mean_absolute_percentage_error: 29.9759\n",
      "Epoch 19: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.248993873596191, 47.662811279296875]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.6439 - mean_absolute_percentage_error: 29.9701 - val_loss: 4.2163 - val_mean_absolute_percentage_error: 29.3968 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.5748 - mean_absolute_percentage_error: 29.2173\n",
      "Epoch 20: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.356512069702148, 35.38664245605469]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.5786 - mean_absolute_percentage_error: 29.2233 - val_loss: 3.9298 - val_mean_absolute_percentage_error: 26.7111 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.5612 - mean_absolute_percentage_error: 29.5738\n",
      "Epoch 21: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.6297287940979, 52.96881866455078]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.5601 - mean_absolute_percentage_error: 29.5826 - val_loss: 4.2324 - val_mean_absolute_percentage_error: 29.4796 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.5656 - mean_absolute_percentage_error: 29.2790\n",
      "Epoch 22: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.3901777267456055, 47.645904541015625]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.5681 - mean_absolute_percentage_error: 29.2747 - val_loss: 4.3912 - val_mean_absolute_percentage_error: 30.5029 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.5185 - mean_absolute_percentage_error: 29.0696\n",
      "Epoch 23: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.788216590881348, 41.395111083984375]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.5182 - mean_absolute_percentage_error: 29.0597 - val_loss: 3.8185 - val_mean_absolute_percentage_error: 26.4965 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 6.3958 - mean_absolute_percentage_error: 28.8541\n",
      "Epoch 24: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.0700178146362305, 43.680179595947266]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3958 - mean_absolute_percentage_error: 28.8541 - val_loss: 4.3195 - val_mean_absolute_percentage_error: 30.0774 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.5324 - mean_absolute_percentage_error: 29.6255\n",
      "Epoch 25: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.6687331199646, 51.62284851074219]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.5322 - mean_absolute_percentage_error: 29.6631 - val_loss: 4.3595 - val_mean_absolute_percentage_error: 30.4719 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 6.3750 - mean_absolute_percentage_error: 28.9242\n",
      "Epoch 26: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.127813816070557, 44.17790603637695]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3750 - mean_absolute_percentage_error: 28.9242 - val_loss: 4.0305 - val_mean_absolute_percentage_error: 28.1548 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.3568 - mean_absolute_percentage_error: 28.8095\n",
      "Epoch 27: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.761445999145508, 37.20328903198242]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3581 - mean_absolute_percentage_error: 28.8117 - val_loss: 4.1516 - val_mean_absolute_percentage_error: 28.8082 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.3904 - mean_absolute_percentage_error: 28.8335\n",
      "Epoch 28: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.648332118988037, 35.29640197753906]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3929 - mean_absolute_percentage_error: 28.8310 - val_loss: 4.6327 - val_mean_absolute_percentage_error: 31.1920 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.3177 - mean_absolute_percentage_error: 28.6955\n",
      "Epoch 29: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.069494247436523, 42.81242752075195]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3182 - mean_absolute_percentage_error: 28.7023 - val_loss: 4.3793 - val_mean_absolute_percentage_error: 30.5472 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.3084 - mean_absolute_percentage_error: 28.2790\n",
      "Epoch 30: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.839866638183594, 43.28511047363281]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3060 - mean_absolute_percentage_error: 28.2699 - val_loss: 4.0290 - val_mean_absolute_percentage_error: 27.9807 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.7834 - mean_absolute_percentage_error: 30.4579\n",
      "Epoch 31: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.257778167724609, 43.54066848754883]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.7826 - mean_absolute_percentage_error: 30.4617 - val_loss: 4.4050 - val_mean_absolute_percentage_error: 30.3754 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "784/786 [============================>.] - ETA: 0s - loss: 6.3165 - mean_absolute_percentage_error: 28.4836\n",
      "Epoch 32: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [6.094436168670654, 54.78113555908203]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3139 - mean_absolute_percentage_error: 28.4894 - val_loss: 4.9872 - val_mean_absolute_percentage_error: 34.8275 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 6.3219 - mean_absolute_percentage_error: 28.1631\n",
      "Epoch 33: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.518095970153809, 37.06562805175781]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.3219 - mean_absolute_percentage_error: 28.1631 - val_loss: 3.9230 - val_mean_absolute_percentage_error: 26.9468 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.1878 - mean_absolute_percentage_error: 28.0311\n",
      "Epoch 34: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.277288436889648, 35.22292709350586]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.1877 - mean_absolute_percentage_error: 28.0268 - val_loss: 3.9509 - val_mean_absolute_percentage_error: 27.0988 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.2109 - mean_absolute_percentage_error: 27.9293\n",
      "Epoch 35: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.514286041259766, 40.08320236206055]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 6.2092 - mean_absolute_percentage_error: 27.9222 - val_loss: 3.8274 - val_mean_absolute_percentage_error: 26.3782 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 6.1126 - mean_absolute_percentage_error: 27.5737\n",
      "Epoch 36: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.615152835845947, 40.91001892089844]\n",
      "786/786 [==============================] - 13s 17ms/step - loss: 6.1097 - mean_absolute_percentage_error: 27.5737 - val_loss: 4.1118 - val_mean_absolute_percentage_error: 28.7328 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.7808 - mean_absolute_percentage_error: 25.9517\n",
      "Epoch 37: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [3.9445393085479736, 32.34065246582031]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.7831 - mean_absolute_percentage_error: 25.9500 - val_loss: 3.7921 - val_mean_absolute_percentage_error: 25.9268 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.7365 - mean_absolute_percentage_error: 25.9975\n",
      "Epoch 38: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.460225582122803, 38.191349029541016]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.7359 - mean_absolute_percentage_error: 25.9886 - val_loss: 4.0354 - val_mean_absolute_percentage_error: 27.6843 - lr: 5.0000e-04\n",
      "Epoch 39/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.7291 - mean_absolute_percentage_error: 26.2001\n",
      "Epoch 39: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.696696758270264, 39.693172454833984]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.7298 - mean_absolute_percentage_error: 26.2005 - val_loss: 4.0719 - val_mean_absolute_percentage_error: 28.2638 - lr: 5.0000e-04\n",
      "Epoch 40/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.7855 - mean_absolute_percentage_error: 25.9437\n",
      "Epoch 40: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.806090354919434, 40.473262786865234]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.7841 - mean_absolute_percentage_error: 25.9333 - val_loss: 4.2255 - val_mean_absolute_percentage_error: 29.2461 - lr: 5.0000e-04\n",
      "Epoch 41/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.6518 - mean_absolute_percentage_error: 25.5019\n",
      "Epoch 41: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.058248996734619, 45.11821746826172]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.6507 - mean_absolute_percentage_error: 25.5108 - val_loss: 4.2148 - val_mean_absolute_percentage_error: 29.3180 - lr: 5.0000e-04\n",
      "Epoch 42/500\n",
      "784/786 [============================>.] - ETA: 0s - loss: 5.6831 - mean_absolute_percentage_error: 25.8757\n",
      "Epoch 42: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.854724884033203, 42.06019973754883]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.6823 - mean_absolute_percentage_error: 25.8571 - val_loss: 4.3948 - val_mean_absolute_percentage_error: 30.7143 - lr: 5.0000e-04\n",
      "Epoch 43/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.7043 - mean_absolute_percentage_error: 25.8551\n",
      "Epoch 43: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [3.962684154510498, 32.62839889526367]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.7039 - mean_absolute_percentage_error: 25.8555 - val_loss: 3.9429 - val_mean_absolute_percentage_error: 27.0014 - lr: 5.0000e-04\n",
      "Epoch 44/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.6617 - mean_absolute_percentage_error: 25.7683\n",
      "Epoch 44: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.5219573974609375, 37.944114685058594]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.6591 - mean_absolute_percentage_error: 25.7600 - val_loss: 3.9498 - val_mean_absolute_percentage_error: 27.2039 - lr: 5.0000e-04\n",
      "Epoch 45/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5754 - mean_absolute_percentage_error: 25.3349\n",
      "Epoch 45: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [3.9951815605163574, 31.616329193115234]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5744 - mean_absolute_percentage_error: 25.3458 - val_loss: 4.1355 - val_mean_absolute_percentage_error: 28.0181 - lr: 5.0000e-04\n",
      "Epoch 46/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5753 - mean_absolute_percentage_error: 25.3264\n",
      "Epoch 46: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.496837139129639, 39.80537414550781]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5751 - mean_absolute_percentage_error: 25.3358 - val_loss: 4.0484 - val_mean_absolute_percentage_error: 28.0515 - lr: 5.0000e-04\n",
      "Epoch 47/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5573 - mean_absolute_percentage_error: 25.1092\n",
      "Epoch 47: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.123256206512451, 34.583030700683594]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5543 - mean_absolute_percentage_error: 25.1014 - val_loss: 3.8211 - val_mean_absolute_percentage_error: 26.1429 - lr: 5.0000e-04\n",
      "Epoch 48/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5960 - mean_absolute_percentage_error: 25.2994\n",
      "Epoch 48: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.724008560180664, 42.62983703613281]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5942 - mean_absolute_percentage_error: 25.2972 - val_loss: 3.7822 - val_mean_absolute_percentage_error: 26.4155 - lr: 5.0000e-04\n",
      "Epoch 49/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5765 - mean_absolute_percentage_error: 25.3430\n",
      "Epoch 49: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.409572601318359, 37.44126892089844]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5739 - mean_absolute_percentage_error: 25.3362 - val_loss: 3.8524 - val_mean_absolute_percentage_error: 26.6723 - lr: 5.0000e-04\n",
      "Epoch 50/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5558 - mean_absolute_percentage_error: 25.0116\n",
      "Epoch 50: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.722270965576172, 41.593929290771484]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5531 - mean_absolute_percentage_error: 25.0090 - val_loss: 3.9398 - val_mean_absolute_percentage_error: 27.3250 - lr: 5.0000e-04\n",
      "Epoch 51/500\n",
      "784/786 [============================>.] - ETA: 0s - loss: 5.5310 - mean_absolute_percentage_error: 25.3672\n",
      "Epoch 51: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.477002143859863, 38.977821350097656]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5284 - mean_absolute_percentage_error: 25.3537 - val_loss: 3.9285 - val_mean_absolute_percentage_error: 27.3510 - lr: 5.0000e-04\n",
      "Epoch 52/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.4864 - mean_absolute_percentage_error: 24.8273\n",
      "Epoch 52: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.190448760986328, 33.18254089355469]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.4876 - mean_absolute_percentage_error: 24.8304 - val_loss: 4.2710 - val_mean_absolute_percentage_error: 29.4298 - lr: 5.0000e-04\n",
      "Epoch 53/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5468 - mean_absolute_percentage_error: 25.2118\n",
      "Epoch 53: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.727457523345947, 40.89921569824219]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5463 - mean_absolute_percentage_error: 25.2096 - val_loss: 4.0402 - val_mean_absolute_percentage_error: 28.2444 - lr: 5.0000e-04\n",
      "Epoch 54/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5135 - mean_absolute_percentage_error: 24.7914\n",
      "Epoch 54: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.241527557373047, 35.81440353393555]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5136 - mean_absolute_percentage_error: 24.7796 - val_loss: 3.7540 - val_mean_absolute_percentage_error: 25.7358 - lr: 5.0000e-04\n",
      "Epoch 55/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5603 - mean_absolute_percentage_error: 25.2459\n",
      "Epoch 55: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [4.553060531616211, 37.216121673583984]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.5587 - mean_absolute_percentage_error: 25.2492 - val_loss: 4.2141 - val_mean_absolute_percentage_error: 29.2411 - lr: 5.0000e-04\n",
      "Epoch 56/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.5061 - mean_absolute_percentage_error: 25.1840\n",
      "Epoch 56: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [5.625502109527588, 50.94984436035156]\n",
      "786/786 [==============================] - 13s 17ms/step - loss: 5.5058 - mean_absolute_percentage_error: 25.1812 - val_loss: 4.5102 - val_mean_absolute_percentage_error: 31.8607 - lr: 5.0000e-04\n",
      "Epoch 57/500\n",
      "785/786 [============================>.] - ETA: 0s - loss: 5.2714 - mean_absolute_percentage_error: 24.3740\n",
      "Epoch 57: val_loss did not improve from 3.72977\n",
      "extra_val_loss: [3.9649462699890137, 32.66231155395508]\n",
      "786/786 [==============================] - 13s 16ms/step - loss: 5.2718 - mean_absolute_percentage_error: 24.3740 - val_loss: 3.8118 - val_mean_absolute_percentage_error: 26.3507 - lr: 2.5000e-04\n",
      "Epoch 58/500\n",
      "786/786 [==============================] - ETA: 0s - loss: 5.2631 - mean_absolute_percentage_error: 24.2136\n",
      "Epoch 58: val_loss did not improve from 3.72977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/cerea_raid/users/dumontj/dev/coco2/dl/main.py:32\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_loss\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mmain_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/main.py:90\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[0;34m(cfg_passthrough)\u001b[0m\n\u001b[1;32m     86\u001b[0m     _flush_loggers()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# no return value from run_hydra() as it may sometime actually run the task_function\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# multiple times (--multirun)\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[43m_run_hydra\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/_internal/utils.py:394\u001b[0m, in \u001b[0;36m_run_hydra\u001b[0;34m(args, args_parser, task_function, config_path, config_name, caller_stack_depth)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmultirun:\n\u001b[1;32m    393\u001b[0m     run_mode \u001b[38;5;241m=\u001b[39m hydra\u001b[38;5;241m.\u001b[39mget_mode(config_name\u001b[38;5;241m=\u001b[39mconfig_name, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[0;32m--> 394\u001b[0m     \u001b[43m_run_app\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultirun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultirun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhydra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhydra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mcfg:\n\u001b[1;32m    404\u001b[0m     run_and_report(\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: hydra\u001b[38;5;241m.\u001b[39mshow_cfg(\n\u001b[1;32m    406\u001b[0m             config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/_internal/utils.py:457\u001b[0m, in \u001b[0;36m_run_app\u001b[0;34m(run, multirun, mode, hydra, config_name, task_function, overrides)\u001b[0m\n\u001b[1;32m    454\u001b[0m         overrides\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhydra.mode=MULTIRUN\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m RunMode\u001b[38;5;241m.\u001b[39mRUN:\n\u001b[0;32m--> 457\u001b[0m     \u001b[43mrun_and_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     run_and_report(\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: hydra\u001b[38;5;241m.\u001b[39mmultirun(\n\u001b[1;32m    467\u001b[0m             config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    470\u001b[0m         )\n\u001b[1;32m    471\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/_internal/utils.py:219\u001b[0m, in \u001b[0;36mrun_and_report\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_and_report\u001b[39m(func: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_env_set(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHYDRA_FULL_ERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_under_debugger():\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/_internal/utils.py:458\u001b[0m, in \u001b[0;36m_run_app.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    454\u001b[0m         overrides\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhydra.mode=MULTIRUN\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m RunMode\u001b[38;5;241m.\u001b[39mRUN:\n\u001b[1;32m    457\u001b[0m     run_and_report(\n\u001b[0;32m--> 458\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mhydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     run_and_report(\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: hydra\u001b[38;5;241m.\u001b[39mmultirun(\n\u001b[1;32m    467\u001b[0m             config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    470\u001b[0m         )\n\u001b[1;32m    471\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/_internal/hydra.py:119\u001b[0m, in \u001b[0;36mHydra.run\u001b[0;34m(self, config_name, task_function, overrides, with_log_configuration)\u001b[0m\n\u001b[1;32m    116\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m Callbacks(cfg)\n\u001b[1;32m    117\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_run_start(config\u001b[38;5;241m=\u001b[39mcfg, config_name\u001b[38;5;241m=\u001b[39mconfig_name)\n\u001b[0;32m--> 119\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhydra_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHydraContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_dir_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhydra.run.dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_subdir_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfigure_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_log_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_run_end(config\u001b[38;5;241m=\u001b[39mcfg, config_name\u001b[38;5;241m=\u001b[39mconfig_name, job_return\u001b[38;5;241m=\u001b[39mret)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# access the result to trigger an exception in case the job failed.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/hydra/core/utils.py:186\u001b[0m, in \u001b[0;36mrun_job\u001b[0;34m(task_function, config, job_dir_key, job_subdir_key, hydra_context, configure_logging)\u001b[0m\n\u001b[1;32m    184\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_job_start(config\u001b[38;5;241m=\u001b[39mconfig, task_function\u001b[38;5;241m=\u001b[39mtask_function)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     ret\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m \u001b[43mtask_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     ret\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m JobStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/cerea_raid/users/dumontj/dev/coco2/dl/main.py:24\u001b[0m, in \u001b[0;36mmain_train\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     22\u001b[0m initiate_wb(cfg)\n\u001b[1;32m     23\u001b[0m model_trainer \u001b[38;5;241m=\u001b[39m Model_training_manager(cfg)\n\u001b[0;32m---> 24\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model_trainer\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Run ends \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/cerea_raid/users/dumontj/dev/coco2/dl/model_training.py:211\u001b[0m, in \u001b[0;36mModel_training_manager.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model with the training data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_val_loss()\n",
      "File \u001b[0;32m/cerea_raid/users/dumontj/dev/coco2/dl/model_training.py:48\u001b[0m, in \u001b[0;36mTrainer.train_model\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel, data: Data_train) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel:\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train model and evaluate validation.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cbk \u001b[38;5;129;01min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cbk \u001b[38;5;129;01min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cbk \u001b[38;5;129;01min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/keras/engine/training.py:1712\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m     }\n\u001b[1;32m   1710\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1712\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1713\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 454\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cerea_raid/users/dumontj/dev/coco2/dl/include/callbacks.py:125\u001b[0m, in \u001b[0;36mExtraValidation.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    124\u001b[0m     (extra_val_data, extra_val_targets) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_val_data\n\u001b[0;32m--> 125\u001b[0m     extra_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_val_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_val_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_val_loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra_val_loss)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(extra_val_loss) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/keras/engine/training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2037\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2038\u001b[0m ):\n\u001b[1;32m   2039\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2040\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2042\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_call_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:2101\u001b[0m, in \u001b[0;36mConcreteFunction._build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2098\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;66;03m# Replace outputs with results, skipping over any 'None' values.\u001b[39;00m\n\u001b[0;32m-> 2101\u001b[0m outputs_list \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2103\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(outputs_list):\n",
      "File \u001b[0;32m~/mambaforge/envs/gpu/lib/python3.9/site-packages/tensorflow/python/util/nest.py:454\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    453\u001b[0m expand_composites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run main.py +experiment=inv_lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2153e1-18db-4b77-bff7-d8ca45a8dfda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3413748b5e49ce5f16477647b547d9baa535cdc90ddd5f67f19155b053a6b1b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
